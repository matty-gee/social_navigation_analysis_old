{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/social_navigation_analysis/lib/python3.10/site-packages/openpyxl/worksheet/_read_only.py:79: UserWarning: Unknown extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "//anaconda3/envs/social_navigation_analysis/lib/python3.10/site-packages/openpyxl/worksheet/_read_only.py:79: UserWarning: Unknown extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    }
   ],
   "source": [
    "import os, sys, glob\n",
    "from pathlib import Path\n",
    "user = os.path.expanduser('~')\n",
    "sys.path.insert(0, '..')\n",
    "sys.path.insert(0, str(Path(f'{user}/Dropbox/Projects/social_navigation_analysis/social_navigation_analysis'))) # directory to social_navigation_analysis\n",
    "\n",
    "# load in preprocessing stuff\n",
    "import info as snt_info\n",
    "import preprocess as snt_preprc\n",
    "import utils as snt_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Parse experiment files into usable data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IN-PERSON: Cogent logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# log_dir = str(Path(f'{user}/Dropbox/Projects/social_navigation_task/data/example_logs'))\n",
    "# logs    = glob.glob(f'{log_dir}/*.log')\n",
    "# print(f'found {len(logs)} log files')\n",
    "# for log in logs:\n",
    "#     snt_preprc.parse_log(log, experimenter='kb', out_dir=log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONLINE: Pavlovia CSVs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple versions of the task\n",
    "Requires snt_version argument "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# csv_dir = str(Path(f'{user}/Dropbox/Projects/social_navigation_task/data/example_csvs'))\n",
    "# csvs    = glob.glob(f'{csv_dir}/*.csv')\n",
    "# print(f'found {len(csvs)} csv files')\n",
    "\n",
    "# for csv in csvs:\n",
    "#     if 'Adolescent' in csv:\n",
    "#         snt_version = 'adolescent_pilot'\n",
    "#     elif 'Prolific' in csv:\n",
    "#         snt_version = 'standard'\n",
    "#     elif 'Schema' in csv:\n",
    "#         snt_version = 'schema'\n",
    "#     print(csv, snt_version)\n",
    "#     snt_preprc.parse_csv(csv, snt_version=snt_version, out_dir=csv_dir) # wrapper for ParseCsv class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adolescent pilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75 csvs\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthew/opt/anaconda3/envs/social_navigation_task/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n",
      "Subject (nan) does not have a \"snt_choice\" column. Exiting without parsing.\n"
     ]
    }
   ],
   "source": [
    "base_dir = f'{user}/Desktop/adolescent_pilot'\n",
    "csv_dir  = f'{base_dir}/CSVs' # specify the data directory\n",
    "csvs     = [f for f in glob.glob(f'{csv_dir}/*.csv') if '~$' not in f]\n",
    "print(f'Found {len(csvs)} csvs')\n",
    "\n",
    "for csv in csvs:\n",
    "    snt_preprc.parse_csv(csv, snt_version='adolescent_pilot', out_dir=base_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Compute behavioral measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36 xlsxs\n",
      "Computing behavior for test_initials\n",
      "Computing behavior for Test_SB_initials\n"
     ]
    }
   ],
   "source": [
    "base_dir = f'{user}/Desktop/adolescent_pilot'\n",
    "xlsxs    = [f for f in glob.glob(f'{base_dir}/Organized/*.xlsx') if '~$' not in f]\n",
    "print(f'Found {len(xlsxs)} xlsxs')\n",
    "\n",
    "for i, xlsx in enumerate(xlsxs):\n",
    "    \n",
    "    # check if file is already computed: \n",
    "    sub_id  = xlsx.split('SNT_')[1].split('.xlsx')[0]\n",
    "    outname = f'{base_dir}/Behavior/SNT_{sub_id}_behavior.xlsx'\n",
    "    if not os.path.isfile(outname):\n",
    "        \n",
    "        print(f'Computing behavior for {sub_id}')\n",
    "        snt_preprc.compute_behavior(file_path=xlsx, out_dir=base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Summarize behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing 35 of 35\r"
     ]
    }
   ],
   "source": [
    "base_dir = f'{user}/Desktop/adolescent_pilot'\n",
    "xlsxs    = [f for f in glob.glob(f'{base_dir}/Behavior/*.xlsx') if '~$' not in f]\n",
    "snt_preprc.summarize_behavior(xlsxs, out_dir=base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - RDVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_original/Data/SNT/Behavior/SNT_10_behavior.xlsx\n",
      "Creating subdirectory for RDVs\n",
      "/Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_original/Data/SNT/Behavior/SNT_13_behavior.xlsx\n",
      "/Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_original/Data/SNT/Behavior/SNT_14_behavior.xlsx\n",
      "/Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_original/Data/SNT/Behavior/SNT_15_behavior.xlsx\n",
      "/Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_original/Data/SNT/Behavior/SNT_16_behavior.xlsx\n",
      "/Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_original/Data/SNT/Behavior/SNT_17_behavior.xlsx\n",
      "/Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_original/Data/SNT/Behavior/SNT_19_behavior.xlsx\n",
      "/Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_original/Data/SNT/Behavior/SNT_20_behavior.xlsx\n",
      "/Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_original/Data/SNT/Behavior/SNT_21_behavior.xlsx\n",
      "/Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_original/Data/SNT/Behavior/SNT_01_behavior.xlsx\n",
      "/Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_original/Data/SNT/Behavior/SNT_02_behavior.xlsx\n",
      "/Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_original/Data/SNT/Behavior/SNT_03_behavior.xlsx\n",
      "/Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_original/Data/SNT/Behavior/SNT_04_behavior.xlsx\n",
      "/Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_original/Data/SNT/Behavior/SNT_05_behavior.xlsx\n",
      "/Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_original/Data/SNT/Behavior/SNT_07_behavior.xlsx\n",
      "/Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_original/Data/SNT/Behavior/SNT_08_behavior.xlsx\n",
      "/Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_original/Data/SNT/Behavior/SNT_09_behavior.xlsx\n",
      "/Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_original/Data/SNT/Behavior/SNT_11_behavior.xlsx\n",
      "/Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_original/Data/SNT/Behavior/SNT_12_behavior.xlsx\n",
      "/Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_original/Data/SNT/Behavior/SNT_06_behavior.xlsx\n",
      "/Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_original/Data/SNT/Behavior/SNT_18_behavior.xlsx\n"
     ]
    }
   ],
   "source": [
    "base_dir  = '/Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_original/Data/SNT'\n",
    "beh_dir   = f'{base_dir}/Behavior'\n",
    "beh_files = glob.glob(beh_dir + '/*.xlsx')\n",
    "for beh_file in beh_files:\n",
    "    print(beh_file)\n",
    "    snt_preprc.compute_rdvs(beh_file, metric='euclidean', output_all=False, out_dir=base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEV: combine all into pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTSD\n",
      "Found 58 files\n",
      "Summarizing 58 of 58ior\r"
     ]
    }
   ],
   "source": [
    "# TODO: run through all samples with this as a .py...\n",
    "# more unittests...\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "synapse_dir = '/Volumes/synapse/projects/SocialSpace/Projects/'\n",
    "datasets    = pd.read_excel(f'{synapse_dir}/SNT_datasets.xlsx')\n",
    "\n",
    "overwrite   = False\n",
    "\n",
    "samples = ['PTSD']\n",
    "\n",
    "#---------------------------\n",
    "# select the project details\n",
    "#---------------------------\n",
    "\n",
    "for sample in samples:\n",
    "\n",
    "    print(sample)\n",
    "\n",
    "    proj_ix = np.where(datasets['sample'].values==sample)[0][0]\n",
    "\n",
    "    project_dir = datasets.loc[proj_ix,'base_directory']\n",
    "    file_format = datasets.loc[proj_ix,'raw_file_format']\n",
    "\n",
    "    # directories etc\n",
    "    datasets.loc[proj_ix, 'raw_directory']        = f'{file_format}'\n",
    "    datasets.loc[proj_ix, 'organized_directory']  = f'Organized'\n",
    "    datasets.loc[proj_ix, 'behavioral_directory'] = f'Behavior'\n",
    "    datasets.loc[proj_ix, 'timing_directory']     = f'Timing'\n",
    "    datasets.loc[proj_ix, 'last_processed']       = datetime.datetime.now()\n",
    "\n",
    "    # find files\n",
    "    raw_files = [f for f in glob.glob(f\"{project_dir}/{datasets.loc[0, 'raw_directory']}/*\") if '~$' not in f]\n",
    "    n_raw     = len(raw_files)\n",
    "    print(f'Found {n_raw} files')\n",
    "\n",
    "    errors = []\n",
    "    for raw_fname in raw_files:\n",
    "        \n",
    "        sub_id = raw_fname.split('/')[-1].split('.')[0].split('_')[1]\n",
    "\n",
    "        #-----------------------\n",
    "        # 1 - parse the raw file \n",
    "        #-----------------------\n",
    "        \n",
    "        xlsx_fname = f\"{project_dir}/{datasets.loc[proj_ix, 'organized_directory']}/SNT_{sub_id}.xlsx\"\n",
    "        if not os.path.exists(xlsx_fname):\n",
    "            \n",
    "            print(f'{sub_id}: parsing', end='\\r')\n",
    "            try:\n",
    "                if file_format == 'Logs':\n",
    "                    snt_preprc.parse_log(raw_fname, experimenter=datasets.loc[proj_ix,'experimenter'], output_timing=False, out_dir=project_dir)\n",
    "                elif file_format == 'CSVs':\n",
    "                    snt_preprc.parse_csv(raw_fname, snt_version=datasets.loc[proj_ix,'options_version'], out_dir=project_dir)\n",
    "            except: \n",
    "                errors.append(f'Parsing: {xlsx_fname}')\n",
    "\n",
    "        #---------------------\n",
    "        # 2 - compute behavior\n",
    "        #---------------------\n",
    "        \n",
    "        behav_fname = f\"{project_dir}/{datasets.loc[proj_ix, 'behavioral_directory']}/SNT_{sub_id}_behavior.xlsx\"\n",
    "        if not os.path.exists(behav_fname):\n",
    "            \n",
    "            print(f'{sub_id}: computing behavior', end='\\r')\n",
    "            snt_preprc.compute_behavior(xlsx_fname, weight_types=False, decision_types=False, coord_types=False, out_dir=project_dir)\n",
    "\n",
    "    # count number of files in each\n",
    "    n_xlsx      = len([f for f in glob.glob(f\"{project_dir}/{datasets.loc[proj_ix, 'organized_directory']}/*\") if '~$' not in f])\n",
    "    n_timing    = len([f for f in glob.glob(f\"{project_dir}/{datasets.loc[proj_ix, 'timing_directory']}/*\") if '~$' not in f])\n",
    "    behav_files = [f for f in glob.glob(f\"{project_dir}/{datasets.loc[proj_ix, 'behavioral_directory']}/*\") if '~$' not in f]\n",
    "    n_behavior  = len(behav_files)\n",
    "\n",
    "    if n_raw != n_xlsx: print('There are missing subjects')\n",
    "\n",
    "    datasets.loc[proj_ix, 'n_raw_files']       = n_raw\n",
    "    datasets.loc[proj_ix, 'n_organized_files'] = n_xlsx\n",
    "    datasets.loc[proj_ix, 'n_timing_files']    = n_timing\n",
    "    datasets.loc[proj_ix, 'n_behavior_files']  = n_behavior\n",
    "\n",
    "    #------------------------------\n",
    "    # 3 - summarize across subjects\n",
    "    #------------------------------\n",
    "\n",
    "    snt_preprc.summarize_behavior(behav_files, out_dir=project_dir)\n",
    "\n",
    "    # TODO: add in dots, self-reports, posttask etc automatically... eg, if there is another summary sheet available, add in as an argument to merge on sub_id column?\n",
    "\n",
    "datasets.to_excel(f'{synapse_dir}/SNT_datasets.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEV: Other pieces: memory + dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # maybe save in a json or smething?\n",
    "# samples = {'PD': {'version_key': {1:'FV', 2:'MV'},\n",
    "#                 'memory': {'FV': {'Olivia': 'first', 'Peter': 'second',\n",
    "#                                   'Anthony': 'assistant', 'Newcomb': 'powerful', \n",
    "#                                   'Hayworth': 'boss', 'Kayce':'neutral'},\n",
    "#                             'MV': {'Peter': 'first', 'Olivia': 'second', \n",
    "#                                    'Kayce': 'assistant', 'Newcomb': 'powerful',\n",
    "#                                    'Hayworth': 'boss', 'Anthony':'neutral'}},\n",
    "#                    'dots': {'FV': {'Olivia': 'first', 'Peter': 'second', \n",
    "#                                    'Anthony': 'assistant', 'Newcomb': 'powerful',\n",
    "#                                    'Hayworth': 'boss','Kayce':'neutral'},\n",
    "#                             'MV': {'Peter': 'first', 'Olivia': 'second', \n",
    "#                                    'Kayce': 'assistant', 'Newcomb': 'powerful', \n",
    "#                                    'Hayworth': 'boss','Anthony':'neutral'}}\n",
    "#                   },\n",
    "\n",
    "#         'PTSD': {'version_key': {'1A':'FV', '1B':'FV', '2A':'FV', '2B':'FV', '3A':'MV', '3B':'MV', '4A':'MV', '4B':'MV'},\n",
    "#                 'memory': {'FV': {'Olivia': 'first', 'Peter': 'second',\n",
    "#                                   'Anthony': 'assistant', 'Newcomb': 'powerful', \n",
    "#                                   'Hayworth': 'boss', 'Kayce':'neutral'},\n",
    "#                             'MV': {'Peter': 'first', 'Olivia': 'second', \n",
    "#                                    'Kayce': 'assistant', 'Newcomb': 'powerful',\n",
    "#                                    'Hayworth': 'boss', 'Anthony':'neutral'}},\n",
    "#                    'dots': {'FV': {'Olivia': 'first', 'Peter': 'second', \n",
    "#                                    'Anthony': 'assistant', 'Newcomb': 'powerful',\n",
    "#                                    'Hayworth': 'boss','Kayce':'neutral'},\n",
    "#                             'MV': {'Peter': 'first', 'Olivia': 'second', \n",
    "#                                    'Kayce': 'assistant', 'Newcomb': 'powerful', \n",
    "#                                    'Hayworth': 'boss','Anthony':'neutral'}},\n",
    "#                 'skincolors':  {'1A':['Brown','Brown','Brown','White','White','White'],\n",
    "#                                 '1B':['Brown','White','Brown','White','White','Brown'],\n",
    "#                                 '2A':['White','White','White','Brown','Brown','Brown'],\n",
    "#                                 '2B':['White','Brown','White','Brown','Brown','White'],\n",
    "#                                 '3A':['Brown','Brown','Brown','White','White','White'],\n",
    "#                                 '3B':['Brown','White','Brown','White','White','Brown'],\n",
    "#                                 '4A':['White','White','White','Brown','Brown','Brown'],\n",
    "#                                 '4B':['White','Brown','White','Brown','Brown','White']}\n",
    "#                   },\n",
    "           \n",
    "#            'CUD': {'version_key': {1:'FV', 2:'FV', 3:'MV', 4:'MV'},\n",
    "#                    'memory': {'FV': {'Jessica': 'first', 'Chris': 'second',\n",
    "#                                      'Anthony': 'assistant', 'Newcomb': 'powerful', \n",
    "#                                      'Hayworth': 'boss', 'Kayce':'neutral'},\n",
    "#                                'MV': {'Chris': 'first', 'Jessica': 'second', \n",
    "#                                       'Kayce': 'assistant', 'Newcomb': 'powerful',\n",
    "#                                        'Hayworth': 'boss', 'Anthony':'neutral'}},\n",
    "#                    'dots': {'FV': {'Olivia': 'first', 'Peter': 'second', \n",
    "#                                    'Anthony': 'assistant', 'Newcomb': 'powerful',\n",
    "#                                    'Hayworth': 'boss','Kayce':'neutral'},\n",
    "#                             'MV': {'Peter': 'first', 'Olivia': 'second', \n",
    "#                                    'Kayce': 'assistant', 'Newcomb': 'powerful', \n",
    "#                                    'Hayworth': 'boss','Anthony':'neutral'}},\n",
    "#                    'skincolors': {1:['Brown','Brown','Brown','White','White','Brown'],\n",
    "#                                   2:['White','White','White','Brown','Brown','White'],\n",
    "#                                   3:['Brown','Brown','Brown','White','White','White'],\n",
    "#                                   4:['White','White','White','Brown','Brown','Brown']} # can infer gender from name\n",
    "#                   }\n",
    "#               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory processing completed\n",
      "Found 80 dots jpgs\n",
      "0 subjects dots already processed\n",
      "3 /Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_CUD/Data/Dots/Dots_19014.jpg\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/social_navigation_analysis/lib/python3.10/site-packages/sklearn/manifold/_spectral_embedding.py:260: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 /Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_CUD/Data/Dots/Dots_19002.jpg\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/social_navigation_analysis/lib/python3.10/site-packages/sklearn/manifold/_spectral_embedding.py:260: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 /Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_CUD/Data/Dots/Dots_19005.jpg\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/social_navigation_analysis/lib/python3.10/site-packages/sklearn/manifold/_spectral_embedding.py:260: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 /Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_CUD/Data/Dots/Dots_18009.jpg\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/social_navigation_analysis/lib/python3.10/site-packages/sklearn/manifold/_spectral_embedding.py:260: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 /Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_CUD/Data/Dots/Dots_18018.jpg\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/social_navigation_analysis/lib/python3.10/site-packages/sklearn/manifold/_spectral_embedding.py:260: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 /Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_CUD/Data/Dots/Dots_18017.jpg\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/social_navigation_analysis/lib/python3.10/site-packages/sklearn/manifold/_spectral_embedding.py:260: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 /Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_CUD/Data/Dots/Dots_22002.jpg\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/social_navigation_analysis/lib/python3.10/site-packages/sklearn/manifold/_spectral_embedding.py:260: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n",
      "//anaconda3/envs/social_navigation_analysis/lib/python3.10/site-packages/sklearn/manifold/_spectral_embedding.py:260: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 /Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_CUD/Data/Dots/Dots_22001.jpg\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/social_navigation_analysis/lib/python3.10/site-packages/sklearn/manifold/_spectral_embedding.py:260: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n",
      "//anaconda3/envs/social_navigation_analysis/lib/python3.10/site-packages/sklearn/manifold/_spectral_embedding.py:260: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 /Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_CUD/Data/Dots/Dots_18001.jpg\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/social_navigation_analysis/lib/python3.10/site-packages/sklearn/manifold/_spectral_embedding.py:260: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 /Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_CUD/Data/Dots/Dots_21021.jpg\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/social_navigation_analysis/lib/python3.10/site-packages/sklearn/manifold/_spectral_embedding.py:260: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 /Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_CUD/Data/Dots/Dots_19030.jpg\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/social_navigation_analysis/lib/python3.10/site-packages/sklearn/manifold/_spectral_embedding.py:260: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: /Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_CUD/Data/Dots/Dots_22013.jpg\n",
      "Dots processing completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/social_navigation_analysis/lib/python3.10/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "//anaconda3/envs/social_navigation_analysis/lib/python3.10/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "//anaconda3/envs/social_navigation_analysis/lib/python3.10/site-packages/numpy/core/_methods.py:257: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "//anaconda3/envs/social_navigation_analysis/lib/python3.10/site-packages/sklearn/manifold/_spectral_embedding.py:260: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n",
      "//anaconda3/envs/social_navigation_analysis/lib/python3.10/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py:1592: RuntimeWarning: k >= N for N * N square matrix. Attempting to use scipy.linalg.eigh instead.\n",
      "  warnings.warn(\"k >= N for N * N square matrix. \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# task version. info:\n",
    "synapse_dir = '/Volumes/synapse/projects/SocialSpace/Projects/'\n",
    "task_versions = pd.read_excel(f'{synapse_dir}/SNT_datasets_task-versions.xlsx', sheet_name='CUD')\n",
    "task_versions.sort_values(by='character_role_num', inplace=True)\n",
    "\n",
    "\n",
    "# loop over datasets\n",
    "sample   = 'CUD'\n",
    "data_dir = '/Volumes/synapse/projects/SocialSpace/Projects/SNT-fmri_CUD/Data'\n",
    "info     = pd.read_excel(f'{data_dir}/SNT-task_versions.xlsx')\n",
    "\n",
    "\n",
    "#-----------------------\n",
    "# version details\n",
    "#-----------------------\n",
    "\n",
    "ard\n",
    "\n",
    "#-----------------------\n",
    "# memory\n",
    "#-----------------------\n",
    "\n",
    "# should be the answers to all the questionnaires..?\n",
    "ans = ['powerful','powerful','boss','neutral','first','assistant','first','second','neutral','powerful',\n",
    "       'boss','first','neutral','assistant','assistant','neutral','second','powerful','assistant','second',\n",
    "       'neutral','second','powerful','first','boss','first','boss','assistant','second','boss'] # this will probably be the same for the ptsd sample too?\n",
    "\n",
    "mem_df = pd.read_excel(glob.glob(f'{data_dir}/SNT-memory*_raw.xlsx')[0])\n",
    "n_mem  = len(mem_df)\n",
    "if not os.path.exists(f'{data_dir}/Summary/SNT-memory_n{n_mem}.xlsx'):\n",
    "    \n",
    "    memory_df = []\n",
    "    for s,sub in mem_df.iterrows():\n",
    "\n",
    "        # get correct version\n",
    "        task_ver = task_versions[[c for c in task_versions.columns if f'v{sub.Task_ver}' in c]]\n",
    "        opts     = [x.lower() for x in task_ver[f'v{sub.Task_ver}_name']]\n",
    "     \n",
    "        # score the answers\n",
    "        resps   = np.array([x.lower() for x in list(sub.values[2:])]) \n",
    "        resps   = [snt_info.character_roles[opts.index(r)] for r in resps] # get characte role for each response\n",
    "        correct = (np.array(resps)==np.array(ans)) * 1\n",
    "        acc     = np.mean(correct)\n",
    "\n",
    "        df = pd.DataFrame([sub.Sub_id, sub.Task_ver, acc] + list(correct)).T\n",
    "        df.columns = ['sub_id','task_version','memory_mean'] + [f'memory_{r+1}_{role}' for r,role in enumerate(roles)]\n",
    "        memory_df.append(df)\n",
    "    memory_df = pd.concat(memory_df)\n",
    "    memory_df.to_excel(f'{data_dir}/Summary/SNT-memory_n{len(memory_df)}_processed.xlsx')\n",
    "\n",
    "print('Memory processing completed')\n",
    "\n",
    "\n",
    "#-----------------------\n",
    "# dots\n",
    "#-----------------------\n",
    "\n",
    "dots_dir  = f'{data_dir}/Dots'\n",
    "dots_jpgs = glob.glob(f'{dots_dir}/Dots*jpg')\n",
    "print(f'Found {len(dots_jpgs)} dots jpgs')\n",
    "\n",
    "# append to an existing dots summary if it exists\n",
    "initial_fname = glob.glob(f'{data_dir}/Summary/SNT-dots_n*.xlsx')\n",
    "if len(initial_fname) > 0: \n",
    "    dots_df  = pd.read_excel(initial_fname[0][0])\n",
    "    sub_list = dots_df['sub_id'].values\n",
    "else:\n",
    "    dots_df  = []\n",
    "    sub_list = []\n",
    "    \n",
    "print(f'{len(sub_list)} subjects dots already processed')\n",
    "for j, jpg in enumerate(dots_jpgs):\n",
    "    \n",
    "    sub_id = int(jpg.split('Dots_')[1].split('.jpg')[0])\n",
    "    if sub_id not in sub_list:\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            print(f'{j+1} {jpg}', end=\"\\r\")\n",
    "            df = snt_preprc.process_dots(jpg)[1]\n",
    "            \n",
    "            # get the correct character roles for each dot\n",
    "            sub_ix   = np.where(info['sub_id'].values == sub_id)[0][0]\n",
    "            task_v   = info.loc[sub_ix, 'version'] \n",
    "            task_ver = task_versions[[c for c in task_versions.columns if f'v{task_v}' in c]]\n",
    "            chars    = [x.lower() for x in task_ver[f'v{task_v}_dots-name']]\n",
    "            for k,i in chars.items(): df.columns = df.columns.str.replace(k, i, regex=True) # replace columns\n",
    "\n",
    "            df.insert(0, 'sub_id', sub_id)\n",
    "            dots_df.append(df)\n",
    "            \n",
    "        except:\n",
    "            print(f'ERROR: {jpg}')\n",
    "\n",
    "dots_df = pd.concat(dots_df)\n",
    "dots_df.to_excel(f'{data_dir}/Summary/SNT-dots_n{len(dots_df)}.xlsx', index=False)\n",
    "if len(initial_fname) > 0: os.remove(initial_fname) # replace old w/ new\n",
    "\n",
    "print('Dots processing completed')\n",
    "\n",
    "\n",
    "#-----------------------\n",
    "# merge all\n",
    "#-----------------------\n",
    "\n",
    "summary_files = [f for f in glob.glob(f'{data_dir}/Summary/*') if ('~$' not in f) and ('All-summary') not in f]\n",
    "merged_df     = snt_utils.merge_dfs(summary_files)\n",
    "merged_df     = snt_utils.move_cols_to_front(merged_df, ['sub_id', 'dx'])\n",
    "merged_df.to_excel(f'{data_dir}/Summary/All-summary_n{len(merged_df)}.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine choice data w/ task info [optional]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # if need to merge choice_data w/ task info\n",
    "# import pandas as pd\n",
    "# from preprocess import merge_choice_data\n",
    "\n",
    "# #set directories \n",
    "# orig_dir = str(Path(f'{user}/Documents/social_navigation_task-main/Task_Organized_10.20.22'))\n",
    "# xlsx_dir = str(Path(f'{user}/Documents/social_navigation_task-main/Task_Organized_Final'))\n",
    "\n",
    "# #find files \n",
    "# fnames = [f for f in glob.glob(f'/{orig_dir}/*.xlsx') if '~$' not in f]\n",
    "\n",
    "# for fname in fnames:\n",
    "#     choice_data = pd.read_excel(fname) # load in the xlsx\n",
    "#     merged_choice_data = merge_choice_data(choice_data, decision_cols=['scene_num', 'decision_num','char_decision_num'])\n",
    "#     fname_ = fname.split('/')[-1]\n",
    "#     out_fname = str(Path(f'{user}/Documents/social_navigation_task-main/Task_Organized_Final/snt_{fname_}')) \n",
    "#     merged_choice_data.to_excel(out_fname, index=False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "social_navigation_analysis",
   "language": "python",
   "name": "social_navigation_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "f3f7fb9d13e0b7cd346c5bcfe5de21908f17a2d0dcbd7821a2fa8e4fbf9948e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
