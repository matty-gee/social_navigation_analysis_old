{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/pandas/compat/_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import info, utils, preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slide_num</th>\n",
       "      <th>cogent_slide_num</th>\n",
       "      <th>scene_num</th>\n",
       "      <th>trial_type</th>\n",
       "      <th>dimension</th>\n",
       "      <th>decision_num</th>\n",
       "      <th>char_decision_num</th>\n",
       "      <th>char_role</th>\n",
       "      <th>char_role_num</th>\n",
       "      <th>cogent_opt1</th>\n",
       "      <th>...</th>\n",
       "      <th>cogent_duration</th>\n",
       "      <th>cogent_onset_2015</th>\n",
       "      <th>cogent_offset_2015</th>\n",
       "      <th>cogent_duration_2015</th>\n",
       "      <th>online_opt1_affil</th>\n",
       "      <th>online_opt2_affil</th>\n",
       "      <th>online_opt1_power</th>\n",
       "      <th>online_opt2_power</th>\n",
       "      <th>Opt1_txt_online</th>\n",
       "      <th>Opt2_txt_online</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>slide_4</td>\n",
       "      <td>1</td>\n",
       "      <td>Decision</td>\n",
       "      <td>affil</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>First</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.991</td>\n",
       "      <td>55.972</td>\n",
       "      <td>67.995</td>\n",
       "      <td>12.023</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>YourememberManhewasapain</td>\n",
       "      <td>YourememberYoureallylikedhimbackthen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>slide_6</td>\n",
       "      <td>1</td>\n",
       "      <td>Decision</td>\n",
       "      <td>affil</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>First</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.990</td>\n",
       "      <td>72.001</td>\n",
       "      <td>84.027</td>\n",
       "      <td>12.026</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Hughimforalongmoment</td>\n",
       "      <td>Shakehishandinstead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>slide_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Decision</td>\n",
       "      <td>affil</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>First</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.990</td>\n",
       "      <td>92.032</td>\n",
       "      <td>104.038</td>\n",
       "      <td>12.006</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>YupItsbeenawhileImstillgettingsettled</td>\n",
       "      <td>YupWeshouldcatchupHowaboutdinnersoon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   slide_num cogent_slide_num  scene_num trial_type dimension  decision_num  \\\n",
       "0          4          slide_4          1   Decision     affil             1   \n",
       "1          6          slide_6          1   Decision     affil             2   \n",
       "2          8          slide_8          1   Decision     affil             3   \n",
       "\n",
       "   char_decision_num char_role  char_role_num  cogent_opt1  ...  \\\n",
       "0                  1     First              1          1.0  ...   \n",
       "1                  2     First              1          1.0  ...   \n",
       "2                  3     First              1          1.0  ...   \n",
       "\n",
       "   cogent_duration  cogent_onset_2015  cogent_offset_2015  \\\n",
       "0           11.991             55.972              67.995   \n",
       "1           11.990             72.001              84.027   \n",
       "2           11.990             92.032             104.038   \n",
       "\n",
       "   cogent_duration_2015  online_opt1_affil  online_opt2_affil  \\\n",
       "0                12.023               -1.0                1.0   \n",
       "1                12.026                1.0               -1.0   \n",
       "2                12.006               -1.0                1.0   \n",
       "\n",
       "   online_opt1_power  online_opt2_power  \\\n",
       "0                0.0                0.0   \n",
       "1                0.0                0.0   \n",
       "2                0.0                0.0   \n",
       "\n",
       "                         Opt1_txt_online                       Opt2_txt_online  \n",
       "0               YourememberManhewasapain  YourememberYoureallylikedhimbackthen  \n",
       "1                   Hughimforalongmoment                   Shakehishandinstead  \n",
       "2  YupItsbeenawhileImstillgettingsettled  YupWeshouldcatchupHowaboutdinnersoon  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 CSVs\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import glob\n",
    "from datetime import date\n",
    "import math\n",
    "\n",
    "validated_decisions = pd.read_excel(f'../data/snt_validated_sorted_mem50_n81.xlsx')\n",
    "validated_decisions = validated_decisions.sort_values(by = 'Decision').reset_index(drop=True)\n",
    "\n",
    "# TODO : this ^ is diff for schema....\n",
    "character_roles = info.character_roles + ['neutral']\n",
    "display(info.decision_trials.head(3))\n",
    "\n",
    "# the pavlovia files are in csv\n",
    "csv_dir = '../data/CSVs/'\n",
    "csvs    = [csv for csv in glob.glob(csv_dir + \"/*.csv\")]\n",
    "print(f'Found {len(csvs)} CSVs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read & clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSING judgments: ../data/CSVs/Prolific-initial_older-format.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "//anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    \n",
    "class ParseCsv:\n",
    "    \n",
    "    def __init__(self, csv_fname):\n",
    "\n",
    "        self.csv      = csv_fname\n",
    "        self.data     = pd.read_csv(csv_fname)\n",
    "        self.sub_id   = self.data.prolific_id[0]\n",
    "        self.task_ver = self.data['task_ver'].values[0]\n",
    "    \n",
    "        self.task_functions = {'snt': self.process_snt,\n",
    "                               'memory': self.process_memory,\n",
    "                               'dots': self.process_dots, \n",
    "                               'forced_choice': self.process_forced_choice}\n",
    "                               #'judgments': self.process_character_judgments}\n",
    "\n",
    "\n",
    "        # ordered: ['first', 'second', 'assistant', 'powerful', 'boss', 'neutral']\n",
    "        self.img_sets = {'OFA': ['OlderFemaleBl_2','OlderMaleW_1','OlderMaleBr_2','OlderMaleW_4','OlderFemaleBr_3','OlderFemaleW_1'],\n",
    "                            'OFB': ['OlderFemaleW_2','OlderMaleBr_1','OlderMaleW_5','OlderMaleBl_3','OlderFemaleW_3','OlderFemaleBl_1'], \n",
    "                            'OFC': ['OlderFemaleBl_2','OlderMaleBr_1','OlderMaleBr_4','OlderMaleW_5','OlderFemaleW_3','OlderFemaleW_1'], \n",
    "                            'OFD': ['OlderFemaleW_2','OlderMaleW_1','OlderMaleW_5','OlderMaleBr_3','OlderFemaleBr_3','OlderFemaleBl_1'], \n",
    "                            'OMA': ['OlderMaleBr_2','OlderFemaleW_2','OlderFemaleBr_5','OlderFemaleW_3','OlderMaleBr_1','OlderMaleW_5'], \n",
    "                            'OMB': ['OlderMaleW_1','OlderFemaleBl_2','OlderFemaleW_1','OlderFemaleBl_3','OlderMaleW_4','OlderMaleBr_4'], \n",
    "                            'OMC': ['OlderMaleBr_4','OlderFemaleBl_2','OlderFemaleBl_1','OlderFemaleW_3','OlderMaleW_3','OlderMaleW_5'], \n",
    "                            'OMD': ['OlderMaleW_1','OlderFemaleW_2','OlderFemaleW_1','OlderFemaleBr_5','OlderMaleBr_3','OlderMaleBr_4'], \n",
    "                            'YFA': ['YoungerFemaleBr_1','YoungerMaleW_4','OlderMaleBr_4','YoungerMaleW_3','OlderFemaleBr_5','OlderFemaleW_1'], \n",
    "                            'YFB': ['YoungerFemaleW_3','YoungerMaleBr_2','YoungerMaleW_2','OlderMaleBr_3','OlderFemaleW_4','OlderFemaleBl_1'], \n",
    "                            'YFC': ['YoungerFemaleBr_1','YoungerMaleBr_2','OlderMaleBr_4','OlderMaleW_4','OlderFemaleW_3','OlderFemaleW_1'], \n",
    "                            'YFD': ['YoungerFemaleW_3','YoungerMaleW_4','OlderMaleW_5','OlderMaleBr_3','OlderFemaleBr_5','OlderFemaleBl_1'],\n",
    "                            'YMA': ['YoungerMaleBr_2','YoungerFemaleW_3','OlderFemaleBl_1','OlderFemaleW_4','OlderMaleBr_3','YoungerMaleW_2'],\n",
    "                            'YMB': ['YoungerMaleW_4','YoungerFemaleBr_1','OlderFemaleW_1','OlderFemaleBr_5','YoungerMaleW_3','OlderMaleBr_4'],\n",
    "                            'YMC': ['YoungerMaleBr_2','YoungerFemaleBr_1','OlderFemaleBl_1','OlderFemaleW_3','OlderMaleW_3','OlderMaleW_5'],\n",
    "                            'YMD': ['YoungerMaleW_4','YoungerFemaleW_3','OlderFemaleW_1','OlderFemaleBr_3','OlderMaleBr_3','OlderMaleBr_4']}\n",
    "\n",
    "        self.clean()\n",
    "\n",
    "    def clean(self):\n",
    "        \n",
    "        # data can be two identical rows for some reason\n",
    "        if self.data.shape[0] > 1: \n",
    "            self.data = self.data.iloc[0,:].to_frame().T\n",
    "        \n",
    "        ## standardize naming conventions ##\n",
    "\n",
    "        # make everything lower case\n",
    "        self.data.columns = map(str.lower, self.data.columns)\n",
    "        self.data = self.data.apply(lambda x: x.astype(str).str.lower())\n",
    "\n",
    "        # replace character names in dataframe entries\n",
    "        replace_substrings = {'newcomb':'powerful', 'hayworth':'boss'}\n",
    "\n",
    "        if 'O' in self.task_ver or 'Y' in self.task_ver:  # this doesnt apply to adolescent version...\n",
    "            if 'F' in self.task_ver: \n",
    "                order = ['maya','chris','anthony','newcomb','hayworth','kayce']\n",
    "            else: \n",
    "                order = ['chris','maya','kayce','newcomb','hayworth','anthony']\n",
    "            for name in order: replace_substrings[name] = character_roles[order.index(name)]\n",
    "\n",
    "        self.data.replace(replace_substrings, inplace=True, regex=True) # replace elements\n",
    "        \n",
    "        # replace column headers (incl. w/ character names)\n",
    "        replace_substrings['.'] = '_'\n",
    "        replace_substrings['narrative'] = 'snt'\n",
    "        replace_substrings['demographics'] = 'judgments'\n",
    "        for k,i in replace_substrings.items():\n",
    "            self.data.columns = self.data.columns.str.replace(k,i, regex=True)\n",
    "        \n",
    "        # race judgments may need to be reworked\n",
    "        cols = utils.find_pattern(self.data.columns, 'race_*_*')\n",
    "        if len(cols) > 0: \n",
    "            rename = {}\n",
    "            for col in cols:\n",
    "                split_ = col.split('_')\n",
    "                rename[col] = f'judgment_{split_[1]}_{split_[0]}_{split_[2]}'\n",
    "            self.data.rename(columns=rename, inplace=True)\n",
    "            \n",
    "        return self.data\n",
    "   \n",
    "    def run_pipeline(self):\n",
    "        \n",
    "        possible_tasks = np.array(list(self.task_functions.keys()))\n",
    "        tasks_mask = np.array([any([task in c for c in self.data.columns]) for task in possible_tasks])\n",
    "        tasks = possible_tasks[tasks_mask]\n",
    "\n",
    "        # preprocess the tasks if they completed snt\n",
    "        post_snt = []\n",
    "        if 'snt' not in tasks: \n",
    "            print(f'Subject does not appear to have completed the SNT')\n",
    "        else:\n",
    "            self.task_functions['snt']()\n",
    "            for task in tasks[1:]:\n",
    "                post_snt.append(self.task_functions[task]())\n",
    "        self.post = pd.concat(post_snt, axis=1)\n",
    "        \n",
    "        return [self.snt, self.post]\n",
    "\n",
    "    def process_characters(self):\n",
    "    \n",
    "        # simple classes: masculine & feminine, dark skin & light skin\n",
    "\n",
    "        if 'character_info_' not in self.data.columns: # older version\n",
    "            img_names = [i.lower() for i in self.img_sets[self.task_ver]]\n",
    "        else: # newer version\n",
    "            img_names = [self.data[f'character_info_{r}_img'].values[0].lower() for r in character_roles] # case insensitive\n",
    "\n",
    "        gender_bool    = [any([ss in i for ss in ['girl','woman','female']]) for i in img_names]\n",
    "        skincolor_bool = [any([ss in i for ss in ['br','bl','brown','black','dark']]) for i in img_names]\n",
    "\n",
    "        # make into df\n",
    "        self.characters = pd.concat([pd.DataFrame(np.array(['feminine' if b  else 'masculine' for b in gender_bool])[np.newaxis], \n",
    "                                                    index=[self.sub_id], columns=[f'{r}_gender' for r in character_roles]),\n",
    "                                     pd.DataFrame(np.array(['brown' if b  else 'white' for b in skincolor_bool])[np.newaxis], \n",
    "                                                    index=[self.sub_id], columns=[f'{r}_skincolor' for r in character_roles])], axis=1)\n",
    "                \n",
    "        return self.characters\n",
    " \n",
    "    def process_snt(self):\n",
    "    \n",
    "        snt_bps  = np.array([int(re.sub('[\"\\]\"]', '', d.split(':')[1])) for d in self.data['snt_choices'].values[0].split(',')]) # single column\n",
    "        snt_opts = self.data['snt_opts_order'].values[0].split('\",\"') # split on delimter\n",
    "        self.snt = pd.DataFrame(columns=['decision_num', 'button_press', 'decision', 'affil', 'power'])\n",
    "\n",
    "        for q, question in enumerate(snt_opts):\n",
    "\n",
    "            # organize\n",
    "            opt1    = utils.remove_nontext(question.split(';')[1]) # this delimeter might change?\n",
    "            opt2    = utils.remove_nontext(question.split(';')[2])\n",
    "            sort_ix = np.argsort((opt1, opt2)) # order options alphabetically\n",
    "\n",
    "            # parse the choice\n",
    "            choice   = sort_ix[snt_bps[q] - 1] + 1 # choice -> 1 or 2, depending on alphabetical ordering\n",
    "            decision = validated_decisions.iloc[q]\n",
    "            affl = np.array(decision['Opt{}_Affl_Discrete'.format(int(choice))]) # grab the correct option's affil value\n",
    "            pwr  = np.array(decision['Opt{}_Pwr_Discrete'.format(int(choice))]) # & power\n",
    "            self.snt.loc[q,:] = [q + 1, snt_bps[q], affl + pwr, affl, pwr]\n",
    "\n",
    "        snt_rts = np.array([int(utils.remove_nontext(rt)) for rt in self.data['snt_rts'].values[0].split(',')])\n",
    "        self.snt['reaction_time'] = snt_rts[np.array(validated_decisions['Slide_num']) - 1] / 1000\n",
    "    \n",
    "        self.snt = info.decision_trials[['decision_num','dimension','scene_num','char_role_num','char_decision_num']].merge(self.snt, on='decision_num')\n",
    "        convert_dict = {'decision_num': int,\n",
    "                        'dimension': str,\n",
    "                        'scene_num': int,\n",
    "                        'char_role_num': int,\n",
    "                        'char_decision_num': int,\n",
    "                        'button_press': int,\n",
    "                        'decision': int,\n",
    "                        'affil': int,\n",
    "                        'power': int,\n",
    "                        'reaction_time': float}\n",
    "        self.snt = self.snt.astype(convert_dict)\n",
    "        # snt_df.to_excel(f'{self.data_dir}/Task/Organized/SNT_{self.sub_id}.xlsx', index=False)\n",
    "\n",
    "        return self.snt\n",
    "\n",
    "    def process_memory(self, version='adult'):\n",
    "\n",
    "        cols = [c for c in self.data.columns if 'memory' in c]\n",
    "        if len(cols) == 0:\n",
    "            print('There are no memory columns in the csv')\n",
    "            \n",
    "        else: \n",
    "\n",
    "            # correct answers when questions are alphabetically sorted\n",
    "            # {0: 'first', 1: 'second', 2: 'assistant', 3: 'newcomb', 4: 'hayworth', 5: 'neutral'}\n",
    "            if version == 'adult':\n",
    "                corr = [1,4,5,4,5,0,0,0,4,1,3,3,1,4,5,3,1,0,2,5,5,2,2,2,3,3,0,1,2,4] \n",
    "                # original? : [1,3,5,3,5,0,0,0,3,1,2,2,1,3,5,2,1,0,4,5,5,4,4,4,2,2,0,1,4,3]...????\n",
    "            elif version == 'adolescent':\n",
    "                corr = [1,4,0,5,5,4,0,0,0,4,3,3,3,4,1,5,3,1,2,5,2,5,1,2,2,2,3,0,1,4]\n",
    "            \n",
    "            if 'memory_resps' in cols or 'character_memory' in cols: # older version\n",
    "                # these versions compressed responses into a single column with delimeter\n",
    "                try: \n",
    "                    memory_  = [t.split(';')[1:2] for t in self.data['memory_resps'].values[0].split('\",\"')]\n",
    "                except: \n",
    "                    memory_  = [t.split(';')[1:2] for t in self.data['character_memory'].values[0].split('\",\"')]\n",
    "                ques_ = [m[0].split(':')[0] for m in memory_]\n",
    "                resp_ = [m[0].split(':')[1] for m in memory_]\n",
    "\n",
    "            else: # newer version\n",
    "\n",
    "                ques_  = self.data[[c for c in cols if 'question' in c]].values[0]\n",
    "                resp_  = self.data[[c for c in cols if 'resp' in c]].values[0]\n",
    "            \n",
    "            memory = sorted(list(zip(ques_, resp_)))\n",
    "            self.memory = pd.DataFrame(np.zeros((1,6)), columns=[f'memory_{cr}' for cr in character_roles])\n",
    "            for r, resp in enumerate(memory): \n",
    "                if resp[1] == character_roles[corr[r]]: \n",
    "                    self.memory[f'memory_{character_roles[corr[r]]}'] += 1/5\n",
    "\n",
    "            # combine summary & trial x trial\n",
    "            self.memory['memory_mean'] = np.mean(self.memory.values)\n",
    "            self.memory['memory_rt']   = np.mean(self.data[[c for c in cols if 'rt' in c]].values[0].astype(float) / 1000)\n",
    "            memory_resp_df = pd.DataFrame(np.array([r[1] for r in memory]).reshape(1, -1), \n",
    "                                          columns=[f'memory_{q + 1 :02d}_{character_roles[r]}' for q, r in enumerate(corr)])\n",
    "\n",
    "            self.memory = pd.concat([self.memory, memory_resp_df], axis=1)\n",
    "            self.memory.index = [self.sub_id]\n",
    "            self.memory.insert(0, 'task_ver', self.data['task_ver'].values[0])\n",
    "                \n",
    "            return self.memory\n",
    "    \n",
    "    def process_dots(self):\n",
    "\n",
    "        cols = [c for c in self.data.columns if 'dots' in c]\n",
    "        if len(cols) == 0:\n",
    "            print('There are no dots columns in the csv')\n",
    "            \n",
    "        else: \n",
    "            \n",
    "            self.dots = pd.DataFrame(index=[self.sub_id], columns=[f'{c}_dots_{d}' for c in character_roles for d in ['affil','power']])\n",
    "\n",
    "            # rename & standardize \n",
    "            if 'dots_resps' in cols: # older version \n",
    "                for row in data['dots_resps'].values[0].split(','):\n",
    "                    split_ = row.split(';')\n",
    "                    role = utils.remove_nontext(split_[0].split(':')[0])\n",
    "                    self.dots[f'{role}_dots_affil'] = (float(split_[1].split(':')[1]) - 500)/500\n",
    "                    self.dots[f'{role}_dots_power'] = (500 - float(split_[2].split(':')[1]))/500\n",
    "\n",
    "            else: # newer version \n",
    "                for role in character_roles:\n",
    "                    self.dots[f'{role}_dots_affil'] = (float(self.data[f'dots_{role}_affil'].values[0]) - 500)/500\n",
    "                    self.dots[f'{role}_dots_power'] = (500 - float(self.data[f'dots_{role}_power'].values[0]))/500\n",
    "\n",
    "            # get means\n",
    "            for dim in ['affil','power']:\n",
    "                self.dots[f'dots_{dim}_mean'] = np.mean(self.dots[[c for c in self.dots.columns if dim in c]],1).values[0]\n",
    "                    \n",
    "            return self.dots\n",
    "\n",
    "    def process_forced_choice(self):\n",
    "\n",
    "        cols = [c for c in self.data.columns if 'forced_choice' in c]\n",
    "        if len(cols) == 0:\n",
    "            print('There are no character judgments columns in the csv')\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            choice_df_ = self.data[cols]\n",
    "            n_choices  = int(len(choice_df_.columns) / 3) # 3 cols for each trial\n",
    "\n",
    "            self.forced_choice = pd.DataFrame()\n",
    "            for t in np.arange(0, n_choices):\n",
    "\n",
    "                options = choice_df_[f'forced_choice_{t}_comparison'].values[0].split('_&_')\n",
    "                rt      = float(choice_df_[f'forced_choice_{t}_rt'].values[0])\n",
    "\n",
    "                # organize the responses\n",
    "                resp    = float(choice_df_[f'forced_choice_{t}_resp'].values[0]) - 50 # center\n",
    "                if resp < 0: choice = options[0]\n",
    "                else:        choice = options[1]\n",
    "\n",
    "                ans                   = np.array([0, 0])\n",
    "                options               = sorted(options)\n",
    "                ans_ix                = options.index(choice)\n",
    "                ans[ans_ix]           = np.abs(resp)\n",
    "                ans[np.abs(ans_ix-1)] = -np.abs(resp)\n",
    "\n",
    "                self.forced_choice.loc[0, [f'{options[0]}_v_{options[1]}_{options[0]}']] = ans[0]\n",
    "                self.forced_choice.loc[0, [f'{options[0]}_v_{options[1]}_{options[1]}']] = ans[1]   \n",
    "                self.forced_choice.loc[0, [f'{options[0]}_v_{options[1]}_reaction_time']] = rt\n",
    "\n",
    "            self.forced_choice.index = [self.sub_id]\n",
    "            self.forced_choice.columns = ['forced_choice_' + c for c in self.forced_choice.columns]\n",
    "                \n",
    "            return self.forced_choice\n",
    "\n",
    "        \n",
    "for csv in csvs:\n",
    "    data = pd.read_csv(csv)\n",
    "    parser = ParseCsv(csv)\n",
    "    data_ = parser.data\n",
    "\n",
    "    # testing snt parsing\n",
    "    snt, post = parser.run_pipeline()\n",
    "    # print(f'{csv} snt has shape={snt.shape}')\n",
    "    # display(snt.head(3))\n",
    "\n",
    "    # print(f'{csv} post task has shape={post.shape}')\n",
    "\n",
    "    # testing judgments parsing\n",
    "    # judgements = parser.process_character_judgments()\n",
    "\n",
    "    if len([c for c in data_.columns if 'judgments' in c]) == 0:\n",
    "        print(f'MISSING judgments: {csv}')\n",
    "        break\n",
    "        \n",
    "    # else:\n",
    "    #     parser = ParseCsv(csv)\n",
    "    #     data_ = parser.data\n",
    "    #     characters = parser.process_characters()\n",
    "    #     snt = parser.process_snt()\n",
    "    #     memory = parser.process_memory()\n",
    "    #     dots = parser.process_dots()\n",
    "    #     ratings = parser.process_character_judgments()\n",
    "    #     snt, post = parser.run_pipeline()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no character judgments columns in the csv\n"
     ]
    }
   ],
   "source": [
    "sub_id = '1'\n",
    "for csv in csvs: \n",
    "    \n",
    "    parser = ParseCsv(csv)\n",
    "    data = parser.data\n",
    "    # process_character_judgments(a)\n",
    "\n",
    "    cols = [ccc for ccc in [cc for cc in [c for c in data.columns if 'judgments' in c] if 'resp' in cc] if 'snt_schema_judgments' not in ccc]\n",
    "    if len(cols) == 0:\n",
    "        print('There are no character judgments columns in the csv')\n",
    "        break \n",
    "    else: \n",
    "                    \n",
    "        if len(data[cols]): judgments = data[cols].iloc[0,:].values\n",
    "        else:               judgments = data[cols].values\n",
    "        judgment_cols = [('_').join(j.split('_')[1:3]) for j in cols]\n",
    "        judgments = pd.DataFrame(judgments.reshape(1,-1), \n",
    "                                index=[sub_id], columns=judgment_cols)\n",
    "\n",
    "        # mean of character judgments                   \n",
    "        rating_dims = np.unique([('_').join(j.split('_')[1:]) for j in judgment_cols if 'self' not in j])\n",
    "        for dim in rating_dims: \n",
    "            judgments[f'{dim}_mean'] = np.mean(judgments[[f'{r}_{dim}' for r in character_roles]], axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['valence100', 'stability100', 'arousal68', 'rt7772']\n",
      "['valence50', 'stability72', 'arousal1', 'rt6643']\n",
      "['valence63', 'stability72', 'arousal68', 'rt6838']\n",
      "['valence64', 'stability93', 'arousal51', 'rt6698']\n",
      "['valence77', 'stability91', 'arousal70', 'rt7609']\n",
      "['valence95', 'stability92', 'arousal76', 'rt7303']\n"
     ]
    }
   ],
   "source": [
    "# 'character_dimensions', 'character_relationship', 'character_race'\n",
    "# \n",
    "rows = [char.split(';') for char in parser.data['character_relationship'].values[0].split(',')]\n",
    "for row in rows: \n",
    "    role = utils.remove_nontext(row[0])\n",
    "    print([utils.remove_nontext(r) for r in row[1:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # relationship evaluations\n",
    "# try:\n",
    "#     character_relationship = [char.split(';') for char in data['character_relationship'].values[0].split(',')]\n",
    "# except: \n",
    "#     character_relationship = [char.split(';') for char in data['relationship_feelings'].values[0].split(',')]\n",
    "    \n",
    "# rel_df = pd.DataFrame(index=[sub_id], columns=[char + '_' + rel for char in character_roles for rel in ['arousal','valence','stability']])\n",
    "# for char in character_relationship:\n",
    "#     role = char_roles[char_names.index(remove_nontext(char[0]))]\n",
    "#     for r in range(1,4):\n",
    "#         rel = char[r].split(':')[0]\n",
    "#         rating = float(char[r].split(':')[1])\n",
    "#         rel_df[role + '_' + rel] = rating\n",
    "# for dim in ['arousal','valence','stability']:\n",
    "#     rel_df['mean_' + dim] = np.mean(rel_df[[char + '_' + dim for char in character_roles]].values)\n",
    "\n",
    "# # character evaluations    \n",
    "# dims = ['status', 'competence', 'youthful', 'gender', 'similarity', 'approachable', 'dominant', 'likability', 'trustworthy', 'race']\n",
    "# try:\n",
    "#     resps = [row.split(';') for row in data['character_dimensions'].values[0].split(',')]\n",
    "# except: \n",
    "#     resps = [row.split(';') for row in data['character_ratings'].values[0].split(',')]\n",
    "\n",
    "# dim_df = pd.DataFrame(index=[sub_id], columns=[char + '_' + dim for char in char_roles for dim in dims])\n",
    "# for resp in resps:\n",
    "#     name = remove_nontext(resp[0])\n",
    "#     if name != 'attention':\n",
    "#         role = char_roles[char_names.index(remove_nontext(resp[0]))]\n",
    "#         dim_df[role + '_' + resp[1].split(':')[0]] = int(resp[1].split(':')[1])\n",
    "\n",
    "# for dim in ['status', 'competence', 'youthful', 'gender', 'similarity', 'approachable', 'dominant',\n",
    "\n",
    "#  'likability', 'trustworthy']:\n",
    "#             dim_df['mean_' + dim] = np.mean(dim_df[[char + '_' + dim for char in char_roles]].values)\n",
    "\n",
    "#         # add race\n",
    "#         try:\n",
    "#             char_race = data['character_race'].values[0].split('\",\"')\n",
    "#         except:\n",
    "#             char_race = data['race_categorization'].values[0].split('\",\"')\n",
    "#         for resp in char_race:\n",
    "#             role = char_roles[char_names.index(remove_nontext(resp.split(';')[0].split(',')[0]))]\n",
    "#             dim_df[role + '_race'] = resp.split(';')[1].split(':')[1]\n",
    "\n",
    "\n",
    "#             snt_good = data['storyline_questions.good'].values\n",
    "#             snt_bad = data['storyline_questions.bad'].values\n",
    "#             if 'ug_questions.good' in data:\n",
    "#                 ug_good = data['ug_questions.good'].values\n",
    "#                 ug_bad = data['ug_questions.bad'].values\n",
    "#             else:\n",
    "#                 ug_good = ['nan']\n",
    "#                 ug_bad = ['nan']\n",
    "#             feedback_dfs.append([sub_id, list(snt_good)[0], list(snt_bad)[0], list(ug_good)[0], list(ug_bad)[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "17170a1c842d46f79a15d2f4651692da09dba23a7ada03f3baa74312cb67564b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
