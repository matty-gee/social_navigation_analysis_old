{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthew/opt/anaconda3/envs/social_navigation_task/lib/python3.10/site-packages/openpyxl/worksheet/_read_only.py:79: UserWarning: Unknown extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "/Users/matthew/opt/anaconda3/envs/social_navigation_task/lib/python3.10/site-packages/openpyxl/worksheet/_read_only.py:79: UserWarning: Unknown extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "/Users/matthew/opt/anaconda3/envs/social_navigation_task/lib/python3.10/site-packages/openpyxl/worksheet/_read_only.py:79: UserWarning: Unknown extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    }
   ],
   "source": [
    "from info import * \n",
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80346f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dont count non-responses for averages, etc\n",
    "# responded  = (behav['button_press'] != 0).values[np.newaxis]\n",
    "# mask_affil = (behav['dimension'] == 'affil').values\n",
    "# mask_power = (behav['dimension'] == 'power').values\n",
    "# resp_mask  =  np.vstack([mask_affil, mask_power]).T * responded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71281134",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthew/opt/anaconda3/envs/social_navigation_task/lib/python3.10/site-packages/openpyxl/worksheet/_read_only.py:79: UserWarning: Unknown extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    }
   ],
   "source": [
    "behavior  = pd.read_excel('/Users/matthew/Dropbox/Projects/social_navigation_task/social_navigation_task/../data/example_subject/snt_18001_.xlsx')\n",
    " \n",
    "dim_mask  = np.vstack([(behavior['dimension'] == 'affil').values, (behavior['dimension'] == 'power').values]).T # boolean\n",
    "\n",
    "responded  = (behavior['button_press'] != 0).values[:,np.newaxis]\n",
    "resp_mask  = np.multiply(dim_mask, responded) # boolean\n",
    "decisions  = behavior['decision'].values[:,np.newaxis] * (dim_mask * 1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can specify the more exotic options\n",
    "\n",
    "class ComputeBehavior:\n",
    "\n",
    "    def __init__(self, file_path, weight_types=None, decision_types=None, out_dir=None):\n",
    "    \n",
    "        # annoying warnings that I dont think matter really\n",
    "        from warnings import simplefilter\n",
    "        simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning) # fragmented df\n",
    "        np.seterr(divide='ignore', invalid='ignore') # division by 0 in some of our operations\n",
    "\n",
    "        # out directory\n",
    "        self.out_dir = out_dir\n",
    "        if self.out_dir is None: \n",
    "            self.out_dir = Path(f'{os.getcwd()}/Behavior')\n",
    "        else:\n",
    "            if '/Behavior' not in self.out_dir: \n",
    "                self.out_dir = Path(f'{self.out_dir}/Behavior')\n",
    "        if not os.path.exists(self.out_dir):\n",
    "            print('Creating subdirectory for behavior')\n",
    "            os.makedirs(self.out_dir)\n",
    "\n",
    "        # load in data\n",
    "        self.file_path = Path(file_path)\n",
    "        self.sub_id    = self.file_path.stem.split('_')[1] # expects a filename like 'snt_subid_*'\n",
    "        assert utils.is_numeric(self.sub_id), 'Subject id isnt numeric; check that filename has this pattern: \"snt_subid*.xlsx\"'\n",
    "\n",
    "        if self.file_path.suffix == '.xlsx':  self.behavior = pd.read_excel(self.file_path, engine='openpyxl')\n",
    "        elif self.file_path.suffix == '.xls': self.behavior = pd.read_excel(self.file_path)\n",
    "        elif self.file_path.suffix == '.csv': self.behavior = pd.read_csv(self.file_path)\n",
    "\n",
    "        # define some options\n",
    "        self.weight_types = {'':'constant', '_linear-decay':'linear', '_exponential-decay':'exponential'}\n",
    "        self.wts = list(self.weight_types.keys())\n",
    "        \n",
    "        self.decision_types = {'': self.cumulative_coords, '_prev': self.previous_decisions, '_cf': self.counterfactual_decisions}\n",
    "        self.dts = list(self.decision_types.keys())\n",
    "\n",
    "    def run_pipeline(self):\n",
    "        [self.compute_character(c) for c in [1,2,3,4,5,9]]\n",
    "        self.compute_across_character()\n",
    "        self.behavior.to_excel(Path(f'{self.out_dir}/snt_{self.sub_id}_behavior.xlsx'), index=False)\n",
    "\n",
    "    def weight_decisions(self, decisions, decay='constant'):\n",
    "        ''' \n",
    "            different ways to weight the decisions \n",
    "        '''\n",
    "        nt = len(decisions)\n",
    "        if decay == 'constant':\n",
    "            weights = np.ones(nt)[:,None] # standard weighting with a constant\n",
    "        elif decay == 'linear':\n",
    "            weights = utils.linear_decay(1, 1/nt, nt)[:,None]\n",
    "        elif decay == 'exponential':\n",
    "            weights = utils.exponential_decay(1, 1/nt, nt)[:,None]\n",
    "\n",
    "        return decisions * weights\n",
    "\n",
    "    def cumulative_coords(self, decisions):\n",
    "        ''' mainly just to be able to pass a function like for prev decision etc'''\n",
    "        return decisions.astype(float), np.cumsum(decisions,0).astype(float)\n",
    "\n",
    "    def previous_decisions(self, decisions):\n",
    "\n",
    "        # if on each trial the subj represents the last chosen decision/coordinates\n",
    "        shifted_decisions = _shift_down(decisions, by=1) \n",
    "        shifted_coords    = np.cumsum(shifted_decisions, 0)\n",
    "\n",
    "        return shifted_decisions.astype(float), shifted_coords.astype(float)\n",
    "\n",
    "    def counterfactual_decisions(self, decisions):\n",
    "        # - counterfactual wrt each trial\n",
    "        # -- eg, if on each trial the subj represents the [ultimately] non-chosen decision/coordinates\n",
    "        coords       = np.cumsum(decisions, 0)\n",
    "        prev_coords  = coords - decisions # for each trial, undo the decisions by subtracting to get the prev coords\n",
    "        decisions_cf = -decisions # counterfactual decision\n",
    "        coords_cf    = prev_coords + decisions_cf # counterfactual coordinates: add the cf decision to the previous coordinate \n",
    "\n",
    "        return decisions_cf.astype(float), coords_cf.astype(float)\n",
    "\n",
    "    def cumulative_mean(self, values, count):\n",
    "        return np.cumsum(values, 0) / np.cumsum(count, 0)\n",
    "\n",
    "    def make_3d(self, U, V, ori):\n",
    "        ''' \n",
    "            add 3rd dimension to U & V, as well as to the origin coordinates\n",
    "            U is vector of interest, z-axis will vary w/ number of interactions\n",
    "            ori will be subtracted from U, so its z-axis will also vary w/ number of interactions\n",
    "            V is reference vector, z-axis will remain fixed\n",
    "        '''\n",
    "\n",
    "        num = np.arange(1, len(U) + 1)[np.newaxis]\n",
    "        U   = np.concatenate([U, num], 1) # changes w/ num of interactions\n",
    "        V   = np.repeat(np.hstack([V, 12])[np.newaxis], len(U), 0) # fixed\n",
    "        ori = np.concatenate([np.repeat(ori[np.newaxis], len(U), 0), num], 1) # changes w/ num of interactions     \n",
    "\n",
    "        return U, V, ori                           \n",
    "\n",
    "    def quadrant_overlap(self, coords):\n",
    "        ''' \n",
    "            the percentage overlap of the decision polygon (made by vertices of coordinates) with each of the 4 2D quadrants \n",
    "            sum == 100\n",
    "        '''\n",
    "\n",
    "        quadrants = {'1': np.array([[0,0], [0,6],  [6,0],  [6,6]]),   \n",
    "                     '2': np.array([[0,0], [0,6],  [-6,0], [-6,6]]),\n",
    "                     '3': np.array([[0,0], [0,-6], [-6,0], [-6,-6]]), \n",
    "                     '4': np.array([[0,0], [0,-6], [6,0],  [6,-6]])}\n",
    "\n",
    "        try: \n",
    "            shape   = sp.spatial.ConvexHull(coords)\n",
    "            polygon = geometry.Polygon(coords[shape.vertices]) \n",
    "            overlap = []\n",
    "            for q, C in quadrants.items(): # overlap w/ quadrants\n",
    "                Q = geometry.Polygon(C[sp.spatial.ConvexHull(C).vertices])\n",
    "                overlap.append(polygon.intersection(Q).area/polygon.area) \n",
    "            assert np.sum(overlap) == 100, f'Quadrant overlap percentages should sum to 100% but is {np.sum(overlap)}%'\n",
    "        except:\n",
    "            overlap = [np.nan,np.nan,np.nan,np.nan]\n",
    "        \n",
    "        return overlap\n",
    "\n",
    "    def compute_character(self, c):\n",
    "        ''' \n",
    "            compute w/in character \n",
    "        '''\n",
    "        ixs   = np.where(self.behavior['char_role_num']==c)[0]\n",
    "        behav = self.behavior.loc[ixs,:]\n",
    "\n",
    "        # mask responses\n",
    "        responded = (behav['button_press'] != 0).values[np.newaxis] # dont count non-responses for averages, etc\n",
    "        dim_mask  = np.vstack([(behav['dimension'] == 'affil').values, (behav['dimension'] == 'power').values]).T # boolean\n",
    "        resp_mask = np.multiply(dim_mask, responded) # boolean\n",
    "\n",
    "        # get decisions into shape=(12,2) [or (3,2) for neutral]\n",
    "        if 'affil' not in behav.columns: # backward compatability\n",
    "            decisions = behav['decision'].values[:,np.newaxis] * (dim_mask * 1) \n",
    "        else:\n",
    "            decisions = behav[['affil','power']].values \n",
    "        assert decisions.shape == resp_mask.shape, 'decision and response mask arrays are diff shapes'\n",
    "\n",
    "        #-----------------------------------------\n",
    "        # weight decisions & calculate coordinates\n",
    "        #-----------------------------------------\n",
    "\n",
    "        # loop over diff weighting types \n",
    "        for wt, decay in self.weight_types.items():\n",
    "\n",
    "            ### weight decision updates\n",
    "            decisions_w = self.weight_decisions(decisions, decay=decay)\n",
    "\n",
    "            ### compute specific decision types & coordinates\n",
    "            for dt, dt_func in self.decision_types.items():\n",
    "\n",
    "                decisions, coords = dt_func(decisions_w)\n",
    "                self.behavior.loc[ixs, [f'affil{wt}{dt}', f'power{wt}{dt}']]             = decisions\n",
    "                self.behavior.loc[ixs, [f'affil_coord{wt}{dt}', f'power_coord{wt}{dt}']] = coords\n",
    "\n",
    "                ### cumulative mean along each dimension [-1,+1] ###\n",
    "                cum_resp = np.cumsum(resp_mask, 0)\n",
    "                cum_mean = coords / cum_resp # divide each time point by the response count \n",
    "                if c != 9: # neu will be all nans\n",
    "                    assert np.all(cum_mean[-1,:] == coords[-1,:] / cum_resp[-1,:]), 'cumulative mean is off'\n",
    "                self.behavior.loc[ixs, [f'affil_mean{wt}{dt}', f'power_mean{wt}{dt}']] = cum_mean\n",
    "\n",
    "                ### culumative consistency: how far did they go in the direction they were traveling? [0,1] ###\n",
    "                # 1d consistency = abs value coordinate, scaled by min and max possible coordinate  \n",
    "                minmax = minmax_coords(decisions)   \n",
    "                self.behavior.loc[ixs, [f'affil_consistency{wt}{dt}', f'power_consistency{wt}{dt}']] = (np.abs(cum_mean) - minmax[0]) / (minmax[1] - minmax[0])\n",
    "\n",
    "                # 2d consistency = decision vector length, scaled by min and max possible vector lengths\n",
    "                min_r = np.array([np.linalg.norm(v) for v in minmax[0]])\n",
    "                max_r = np.array([np.linalg.norm(v) for v in minmax[1]])\n",
    "                r     = np.array([np.linalg.norm(v) for v in cum_mean])\n",
    "                self.behavior.loc[ixs, f'consistency{wt}{dt}'] = (r - min_r) / (max_r - min_r)\n",
    "\n",
    "                ### multi-dimensional: angles & distances ###\n",
    "\n",
    "                # directional angles between (ori to poi) and (ori to ref) [optional 3rd dimension]\n",
    "                # - origin (ori)\n",
    "                # --- neu: (0, 0, [interaction # (1:12)]) - note that 'origin' moves w/ interactions if in 3d\n",
    "                # --- pov: (6, 0, [interaction # (1:12)])\n",
    "                # - reference vector (ref)\n",
    "                # --- neu: (6, 0, [max interaction (12)])\n",
    "                # --- pov: (6, 6, [max interaction (12)])\n",
    "                # - point of interaction vector (poi): (curr. affil coord, power coord, [interaction # (1:12)])\n",
    "                # to get directional vetctors (poi-ori), (ref-ori)\n",
    "\n",
    "                ref_frames = {'neu': {'ori': np.array([[0,0]]), 'ref': np.array([[6,0]]), 'dir': False},\n",
    "                              'pov': {'ori': np.array([[6,0]]), 'ref': np.array([[6,6]]), 'dir': None}} \n",
    "                int_num    = np.arange(1, len(behav)+1)[np.newaxis]\n",
    "\n",
    "                for ndim in np.arange(2, 4):    \n",
    "                    for ot in ['neu', 'pov']:\n",
    "\n",
    "                        ## angles between ori-poi & ori-ref\n",
    "                        poi = coords\n",
    "                        ref_frame = ref_frames[ot]\n",
    "                        ref, ori, drn = ref_frame['ref'], ref_frame['ori'], ref_frame['dir']\n",
    "\n",
    "                        # if 3d, add 3rd dimension\n",
    "                        if ndim == 3: \n",
    "                            poi, ref, ori = self.make_3d(self, poi, ref[0], ori)\n",
    "                            drn = None # may not be correct for neutral origin... not sure yet\n",
    "\n",
    "                        # account for origin\n",
    "                        poi = poi - ori\n",
    "                        ref = ref - ori\n",
    "\n",
    "                        # angle between ori-poi & ori-ref\n",
    "                        self.behavior.loc[ixs, f'{ot}{ndim}d_angle{wt}{dt}'] = utils.calculate_angle(poi, ref, direction=drn) # outputs radians\n",
    "\n",
    "                        ## distances from ori-poi\n",
    "                        if ndim == 2: \n",
    "                            self.behavior.loc[ixs, f'{ot}_distance{wt}{dt}'] = [np.linalg.norm(v) for v in poi] # l2 norm is euclidean distance from ori\n",
    "\n",
    "    def compute_across_character(self):\n",
    "        ''' \n",
    "            variables across characters\n",
    "        '''\n",
    "        \n",
    "        for sx in utils.flatten_nested_lists([[f'{wt}{dt}' for dt in self.dts for wt in self.wts]]):\n",
    "            for t in range(0, 63):\n",
    "\n",
    "                X = self.behavior.loc[:t, [f'affil_coord{sx}', f'power_coord{sx}', 'char_decision_num']].values\n",
    "\n",
    "                try: # 3d \n",
    "                    vol = sp.spatial.ConvexHull(X).volume\n",
    "                except: \n",
    "                    vol = np.nan\n",
    "                try: # 2d\n",
    "                    shape   = sp.spatial.ConvexHull(X[:,0:2]) \n",
    "                    perim   = shape.area # perimeter\n",
    "                    area    = shape.volume  # area when 2D\n",
    "                except: \n",
    "                    perim = np.nan\n",
    "                    area  = np.nan\n",
    "\n",
    "                overlap = self.quadrant_overlap(X[:,0:2])\n",
    "\n",
    "                self.behavior.loc[t, f'perimeter{sx}']  = perim\n",
    "                self.behavior.loc[t, f'area{sx}']       = area\n",
    "                self.behavior.loc[t, f'volume{sx}']     = vol\n",
    "                self.behavior.loc[t, f'Q1_overlap{sx}'] = overlap[0]\n",
    "                self.behavior.loc[t, f'Q2_overlap{sx}'] = overlap[1]\n",
    "                self.behavior.loc[t, f'Q3_overlap{sx}'] = overlap[2]\n",
    "                self.behavior.loc[t, f'Q4_overlap{sx}'] = overlap[3]\n",
    "                \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: concatenate the columns in one go for the df\n",
    "\n",
    "from pathlib import Path \n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import scipy.spatial\n",
    "\n",
    "sys.path.insert(0, '../../../toolbox/toolbox')\n",
    "from circ_stats import * \n",
    "from matrices import *\n",
    "\n",
    "# should probably import toolbox so circ_stats etc is available..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def by_character(variable):\n",
    "    ''' return variable name for each character '''\n",
    "    return [variable + '_' + character_roles[c] for c in range(5)]\n",
    "    \n",
    "\n",
    "def chars_df(df, var_name):\n",
    "    ''' subset a df with the different character values for a variable'''\n",
    "    return df[[var_name + '_' + cr for cr in character_roles]]\n",
    "\n",
    "\n",
    "def get_decision_sequence(df):\n",
    "    ''' grab decisions from a summary df'''\n",
    "    return df.loc[0, ['decisions_' + \"{:02d}\".format(t+1) for t in range(63)]]\n",
    "\n",
    "\n",
    "def repeat_array_cols(X, repeats=2):\n",
    "    return np.transpose([X] * repeats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log to more detailed xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = str(Path(f'{pkg_dir}/../data/example_subject/snt_18001.log'))\n",
    "# experimenter = 'KB'\n",
    "# parse_log(file_path, experimenter, output_timing=True, out_dir=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path(f'{pkg_dir}/../data/example_subject/snt_18001.xlsx')\n",
    "compute_behavior(file_path, out_dir=f'{pkg_dir}/../data/example_subject/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for RDVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import compress, product, combinations \n",
    "def combos(arr, k=2):\n",
    "    \"\"\" \n",
    "        arr: np.array to get combos from\n",
    "        r: num of combos\n",
    "    \"\"\"\n",
    "    return list(combinations(arr, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path(f'{pkg_dir}/../data/example_subject/snt_18001_behavior.xlsx')\n",
    "compute_rdvs(file_path, metric='euclidean', out_dir=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summarize all subjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing 1 of 2\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthew/opt/anaconda3/lib/python3.9/site-packages/openpyxl/worksheet/_read_only.py:79: UserWarning: Unknown extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing 2 of 2\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthew/opt/anaconda3/lib/python3.9/site-packages/openpyxl/worksheet/_read_only.py:79: UserWarning: Unknown extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    }
   ],
   "source": [
    "file_paths = [f'{pkg_dir}/../data/example_subject/snt_18001_behavior.xlsx', f'{pkg_dir}/../data/example_subject/snt_18001_behavior.xlsx']\n",
    "out_dir=f'{pkg_dir}/preprocessed_behavior/'\n",
    "\n",
    "summarize_behavior(file_paths, out_dir=out_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('social_navigation_task')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "17170a1c842d46f79a15d2f4651692da09dba23a7ada03f3baa74312cb67564b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
